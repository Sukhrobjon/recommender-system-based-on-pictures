{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://kyso.io/helenadomo/earthquake1-2#code=output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import load_img\n",
    "# from PIL import Image, load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.applications.vgg16 import decode_predictions\n",
    "from keras.applications.vgg16 import VGG16\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "# load the model\n",
    "model = VGG16(weights='imagenet', include_top=False)\n",
    "\n",
    "# model = VGG16(weights='imagenet', include_top=False)\n",
    "# # load an image from file\n",
    "# original_img = load_img(filepath+'9733.jpg', target_size=(224, 224))\n",
    "# # convert the image pixels to a numpy array\n",
    "# nparry_img = img_to_array(original_img)\n",
    "# # # reshape data for the model\n",
    "# # image = nparry_img.reshape((1, nparry_img.shape[0], nparry_img.shape[1], nparry_img.shape[2]))\n",
    "# print(\"image shape:\", nparry_img.shape)\n",
    "# # # prepare the image for the VGG model\n",
    "# image = np.expand_dims(nparry_img, axis=0)\n",
    "# # print(\"image shape:\", image.shape)\n",
    "# processed_image = preprocess_input(image)\n",
    "# print(\"preprocess\")\n",
    "# # print(processed_image)\n",
    "# # predict the probability across all output classes\n",
    "# img_features = model.predict(processed_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"../fashion-product-images-small/images/\"\n",
    "all_image_ids =  get_all_image_ids(filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44441\n"
     ]
    }
   ],
   "source": [
    "print(len(all_image_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_sim_gen(all_ids):\n",
    "    with open('cos_sim_table_2.txt', 'a') as file:\n",
    "        counter = 0\n",
    "        for i in range(len(all_ids)):\n",
    "            for j in range(i+1, len(all_ids)):\n",
    "                image_i = all_ids[i]\n",
    "                image_j = all_ids[j]\n",
    "                image_i = preprocess_image_for_vgg(filepath, image_i)\n",
    "                image_j = preprocess_image_for_vgg(filepath, image_j)\n",
    "                shape_i = model.predict(image_i).reshape(1, -1)\n",
    "                shape_j = model.predict(image_j).reshape(1, -1)\n",
    "#                 yield (all_ids[i], all_ids[j], cosine_similarity(shape_i, shape_j)[0][0])\n",
    "#                 cos_sim = cosine_similarity(shape_i, shape_j)\n",
    "        \n",
    "                file.write( all_ids[i] + \" \" + all_ids[j] + \" \" + str(cosine_similarity(shape_i, shape_j)[0][0])+'\\n')\n",
    "                counter += 1\n",
    "                print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# print(img_features.shape)\n",
    "# # print(img_features.reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n"
     ]
    }
   ],
   "source": [
    "cosine_sim_gen(all_image_ids[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more_stuff = [img_features.reshape(1,-1), img_features.reshape(1,-1)]\n",
    "# # test_cos = create_cosine_table(['a'], more_stuff)\n",
    "# # print(test_cos)\n",
    "# cosine_similarity(more_stuff)\n",
    "# # print(img_features.reshape(1,-1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_i_id</th>\n",
       "      <th>image_j_id</th>\n",
       "      <th>cosine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9733.jpg</td>\n",
       "      <td>14147.jpg</td>\n",
       "      <td>0.141262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9733.jpg</td>\n",
       "      <td>52112.jpg</td>\n",
       "      <td>0.289882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9733.jpg</td>\n",
       "      <td>6400.jpg</td>\n",
       "      <td>0.146407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9733.jpg</td>\n",
       "      <td>34297.jpg</td>\n",
       "      <td>0.281507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9733.jpg</td>\n",
       "      <td>24084.jpg</td>\n",
       "      <td>0.117336</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_i_id image_j_id    cosine\n",
       "0   9733.jpg  14147.jpg  0.141262\n",
       "1   9733.jpg  52112.jpg  0.289882\n",
       "2   9733.jpg   6400.jpg  0.146407\n",
       "3   9733.jpg  34297.jpg  0.281507\n",
       "4   9733.jpg  24084.jpg  0.117336"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('cos_sim_table1.txt', sep=\" \", header=None)\n",
    "df.columns = [\"image_i_id\", 'image_j_id', 'cosine']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = 'styles.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Series.unique of 0                       Shirts\n",
      "1                        Jeans\n",
      "2                      Watches\n",
      "3                  Track Pants\n",
      "4                      Tshirts\n",
      "                 ...          \n",
      "44441             Casual Shoes\n",
      "44442               Flip Flops\n",
      "44443                  Tshirts\n",
      "44444    Perfume and Body Mist\n",
      "44445                  Watches\n",
      "Name: articleType, Length: 44446, dtype: object>\n"
     ]
    }
   ],
   "source": [
    "style_df = pd.read_csv(csv_path)\n",
    "style_df.head()\n",
    "print(style_df['articleType'].unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cosine_similarity(v1, v2):\n",
    "    result = cosine_similarity(v1, v2)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# a = [[2, 0, 1, 1, 0, 2, 1, 1]]\n",
    "\n",
    "# b = [[2, 1, 1, 0, 1, 1, 1, 1]]\n",
    "# img_features = img_features.reshape(1, 7*7*512)\n",
    "# # print(\"yhat shape->\", yhat.shape)\n",
    "\n",
    "# # print(get_cosine_similarity(a, a))\n",
    "# print(\"yhat cos sim: \")\n",
    "# # print(img_features)\n",
    "# print(get_cosine_similarity(img_features, img_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image_for_vgg(filepath, img_id):\n",
    "    \"\"\"\n",
    "    Takes an image and returns 4D array of features from vgg16 model\n",
    "    \n",
    "    Args:\n",
    "        image_path: path to image\n",
    "    \"\"\"\n",
    "    # load an image from file\n",
    "    original_img = load_img(filepath + img_id, target_size=(224, 224))\n",
    "    # convert the image pixels to a numpy array\n",
    "    nparry_img = img_to_array(original_img)\n",
    "    # # reshape data for the model\n",
    "    # image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "#     print(\"image shape:\", nparry_img.shape)\n",
    "    # # prepare the image for the VGG model\n",
    "    image = np.expand_dims(nparry_img, axis=0)\n",
    "    # print(\"image shape:\", image.shape)\n",
    "    processed_image = preprocess_input(image)\n",
    "#     print(\"preprocess\")\n",
    "#     print(processed_image)\n",
    "    # predict the probability across all output classes\n",
    "    \n",
    "    return processed_image\n",
    "\n",
    "\n",
    "def get_feature_vector_from_vgg(processed_image):\n",
    "    # dont use include top for vgg, because we dont want mlp part\n",
    "    model = VGG16(weights='imagenet', include_top=False)\n",
    "    \n",
    "    feature_vector = model.predict(processed_image)\n",
    "    return feature_vector\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2, 0, 1, 1, 0, 2, 1, 1], [2, 1, 1, 0, 1, 1, 1, 1], [2, 3, 6, 1, 0, 2, 8, 0]]\n"
     ]
    }
   ],
   "source": [
    "a = [[2, 0, 1, 1, 0, 2, 1, 1]]\n",
    "b = [[2, 1, 1, 0, 1, 1, 1, 1]]\n",
    "c = [[2, 3, 6, 1, 0, 2, 8, 0]]\n",
    "test_for_cos_df = a + b + c\n",
    "print(test_for_cos_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_image_ids(filepath):\n",
    "    images_ids = []\n",
    "    # listing all the image names into list they are ids of the image\n",
    "    for img in os.listdir(filepath):\n",
    "        if img.endswith('jpg'):\n",
    "            images_ids.append(img)\n",
    "    \n",
    "    return images_ids\n",
    "\n",
    "# reshape the feature_vector so we can find cosine similarity score\n",
    "def reshape_feature_vector(feature_vector):\n",
    "    \"\"\"\n",
    "    Takes 4d array, return 2D representation\n",
    "    \"\"\"\n",
    "    # this is the vgg output 7, 7, 512\n",
    "    return feature_vector.reshape(1, 7*7*512)\n",
    "    \n",
    "# print(reshape_feature_vector(img_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make vgg_feature list \n",
    "def list_of_vgg_features(all_imgs):\n",
    "    # creates the list of vgg features and reshape it ready for making cosine sim score later\n",
    "    all_feature_vectors = []\n",
    "    \n",
    "    for index, img in enumerate(all_imgs):\n",
    "        feature_vector = get_feature_vector_from_vgg(img)\n",
    "        # reshape the feature vector\n",
    "        feature_vector = reshape_feature_vector(feature_vector)\n",
    "        \n",
    "        all_feature_vectors.append(feature_vector)\n",
    "        \n",
    "    # return all feature vectors\n",
    "    return all_imgs, all_feature_vectors\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_cosine_similarity(v1, v2):\n",
    "#     result = cosine_similarity(v1, v2)\n",
    "#     return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cosine_table(list_of_ids, list_of_features):\n",
    "    \"\"\"Creates a cosine similarity table from list of vectors\"\"\"\n",
    "    cos_sims = cosine_similarity(list_of_features)\n",
    "    print(cos_sims)\n",
    "    cos_table = pd.DataFrame(cos_sims, columns=list_of_ids, index=list_of_ids)\n",
    "    # turn the cos sim into dataframe\n",
    "    return cos_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cosine_table(list_vector):\n",
    "    cos_list = []\n",
    "    for i in range(len(list_vector)):\n",
    "        x = np.array(list_vector[i]).reshape(1, -1)\n",
    "        for j in range(len(list_vector)):\n",
    "            y = np.array(list_vector[j]).reshape(1, -1)\n",
    "            score = cosine_similarity(x, y)\n",
    "            cos_list.append(score)\n",
    "    \n",
    "    df_col = [\"a\", \"b\", \"c\"]\n",
    "    idx = [\"a\", \"b\", \"c\"]\n",
    "    print(np.array(cos_list))\n",
    "    cos_df = pd.DataFrame(cos_list, columns=df_col, index=idx)\n",
    "    cos_df.head()\n",
    "    print(cos_list)\n",
    "    \n",
    "\n",
    "\n",
    "# #     cos_df.sort_values(by=df_col, axis=1, ascending=False, inplace=False, kind='quicksort', na_position='last')\n",
    "#     return cos_df\n",
    "# test_cos_table(test_for_cos_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_cos_table = test_cos_table(test_for_cos_df)\n",
    "# test_cos_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_k_most_similar_to(df, given_img, k_similar=5):\n",
    "    # this gets the rows\n",
    "    k_images = df[given_img].sort_values(ascending=False)[1:k_similar+1].index\n",
    "    # this get the corresod=nding scores\n",
    "    k_images_score = df[given_img].sort_values(ascending=False)[1:k_similar+1]\n",
    "    for img in range(len(k_images)):\n",
    "        original = k_images[i]\n",
    "        plt.imshow(original)\n",
    "        plt.show()\n",
    "        print(\"Similarity score:\", k_images_score[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_vectors(iterable):\n",
    "    for item in iterable:\n",
    "        yield item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filepath=\"../fashion-product-images-small/images/\"\n",
    "# list_images = get_all_image_ids(filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_image_generator = generate_vectors(list_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# all_processed_images = []\n",
    "# for i, image in enumerate(all_image_generator):\n",
    "#     processed_image = preprocess_image_for_vgg(filepath, image)\n",
    "#     if i == 40000:\n",
    "#         print(processed_image)\n",
    "#     all_processed_images.append(processed_image)\n",
    "        \n",
    "# # print(all_processed_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(all_processed_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # now make a vgg vectors\n",
    "# all_vgg_features = []\n",
    "# vgg_generator = generate_vectors(all_processed_images)\n",
    "# for image in vgg_generator:\n",
    "#     feature_vector = get_feature_vector_from_vgg(image)\n",
    "#     # reshape it before we put into feature vector\n",
    "#     feature_vector = reshape_feature_vector(feature_vector)\n",
    "#     # now append it to all features list\n",
    "#     all_vgg_features.append(feature_vector.flatten())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_vgg_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all(filepath):\n",
    "    print(\"======================STARTING============================\")\n",
    "    all_images = get_all_image_ids(filepath)\n",
    "    print(\"some examples: \", all_images[:20])\n",
    "    # we preprocess the image to make it ready to pass to vgg model\n",
    "    print(\"prepocess\")\n",
    "    all_processed_images = []\n",
    "#     all_images = np.random.choice(all_images, 5)\n",
    "#     all_images = all_images[:5]\n",
    "#     gen = generate_vectors(all_images)\n",
    "    for image in all_images:\n",
    "        processed_image = preprocess_image_for_vgg(filepath, image)\n",
    "        all_processed_images.append(processed_image)\n",
    "        \n",
    "    print(\"Now we have preprocessed image for vgg\")\n",
    "    all_feature_vectors = []\n",
    "    for image in all_processed_images:\n",
    "        # create feature vector\n",
    "        feature_vector = get_feature_vector_from_vgg(image)\n",
    "#         print(\"making vgg\")\n",
    "        # reshape it before we put into \n",
    "#         print(\"feature shape:\", feature_vector.shape)\n",
    "        feature_vector = reshape_feature_vector(feature_vector)\n",
    "#         print(\"after reshaping\", feature_vector)\n",
    "        \n",
    "        # now append it to all features list\n",
    "        all_feature_vectors.append(feature_vector.flatten())\n",
    "    \n",
    "    print(\"Now we have all feature vector!\")\n",
    "    all_feature_vectors = np.array(all_feature_vectors)\n",
    "    print(\"shape of the feature vector\")\n",
    "    print(all_feature_vectors.shape)\n",
    "#     create cos sim table\n",
    "\n",
    "    \n",
    "    print(\"we have list of features ready to pass cosine similarity!\")\n",
    "    print(\"passing...\")\n",
    "    cos_df = create_cosine_table(all_images, all_feature_vectors)\n",
    "    if len(cos_df) < 2000:\n",
    "        cos_df.to_csv('cos_similarity_small_table.csv', sep='\\t', encoding='utf-8')\n",
    "    else:\n",
    "        cos_df.to_csv('cos_similarity_table.csv', sep='\\t', encoding='utf-8')\n",
    "    return cos_df\n",
    "#     return all_feature_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================STARTING============================\n",
      "some examples:  ['9733.jpg', '14147.jpg', '52112.jpg', '6400.jpg', '34297.jpg', '24084.jpg', '12536.jpg', '54563.jpg', '15259.jpg', '35189.jpg', '44770.jpg', '4217.jpg', '47279.jpg', '36480.jpg', '16750.jpg', '50705.jpg', '26693.jpg', '37946.jpg', '3578.jpg', '40516.jpg']\n",
      "prepocess\n",
      "Now we have preprocessed image for vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n",
      "making vgg\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-2cfabb7658e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"../fashion-product-images-small/images/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# print(result.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-d8bb0f8a0583>\u001b[0m in \u001b[0;36mrun_all\u001b[0;34m(filepath)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_processed_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# create feature vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mfeature_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_feature_vector_from_vgg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"making vgg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m# reshape it before we put into\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-e04de50b3321>\u001b[0m in \u001b[0;36mget_feature_vector_from_vgg\u001b[0;34m(processed_image)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVGG16\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'imagenet'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mfeature_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfeature_vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/ds/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1460\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1461\u001b[0m                                             \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1462\u001b[0;31m                                             callbacks=callbacks)\n\u001b[0m\u001b[1;32m   1463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1464\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m~/.virtualenvs/ds/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps, callbacks)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0mbatch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'batch'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'size'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'predict'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'begin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/ds/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3738\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3739\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3740\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3742\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/ds/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1079\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m     \"\"\"\n\u001b[0;32m-> 1081\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/ds/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1119\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1120\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1121\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/ds/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/ds/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/.virtualenvs/ds/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# filepath = \"../fashion-product-images-small/images/\"\n",
    "# result = run_all(filepath)\n",
    "# # print(result.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9733.jpg     1.000000\n",
       "52112.jpg    0.289882\n",
       "34297.jpg    0.281507\n",
       "Name: 9733.jpg, dtype: float32"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['9733.jpg'].sort_values(ascending=False)[:3].index\n",
    "result['9733.jpg'].sort_values(ascending=False)[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>9733.jpg</th>\n",
       "      <th>14147.jpg</th>\n",
       "      <th>52112.jpg</th>\n",
       "      <th>6400.jpg</th>\n",
       "      <th>34297.jpg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9733.jpg</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.141262</td>\n",
       "      <td>0.289882</td>\n",
       "      <td>0.146407</td>\n",
       "      <td>0.281507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14147.jpg</th>\n",
       "      <td>0.141262</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.149685</td>\n",
       "      <td>0.302827</td>\n",
       "      <td>0.185416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52112.jpg</th>\n",
       "      <td>0.289882</td>\n",
       "      <td>0.149685</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.160585</td>\n",
       "      <td>0.397643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6400.jpg</th>\n",
       "      <td>0.146407</td>\n",
       "      <td>0.302827</td>\n",
       "      <td>0.160585</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.178366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34297.jpg</th>\n",
       "      <td>0.281507</td>\n",
       "      <td>0.185416</td>\n",
       "      <td>0.397643</td>\n",
       "      <td>0.178366</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           9733.jpg  14147.jpg  52112.jpg  6400.jpg  34297.jpg\n",
       "9733.jpg   1.000000   0.141262   0.289882  0.146407   0.281507\n",
       "14147.jpg  0.141262   1.000000   0.149685  0.302827   0.185416\n",
       "52112.jpg  0.289882   0.149685   1.000000  0.160585   0.397643\n",
       "6400.jpg   0.146407   0.302827   0.160585  1.000000   0.178366\n",
       "34297.jpg  0.281507   0.185416   0.397643  0.178366   1.000000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
